
\section{Introduction}
In July 2000, the CAP Theorem \cite{40} was formulated, stating that a highly available system cannot provide strong consistency guarantees in the presence of network partitions. This became a rallying call for a generation of highly scalable but semantically weak system designs. The NoSQL movement embraced this approach, offering production-use data platforms that eschewed strong consistency guarantees, but could scale-out to many servers \cite{21, 25, 33}. The consistency concept used in the CAP theorem came from the distributed systems community, and concerned reading the most recent value of a data item that is replicated across servers. The NoSQL movement implicitly used this to justify a lack of  transaction support, with either no way to group multiple operations  over multiple data items, or else restricting transactions to operations on items known to be colocated. 

Serializability, the gold standard of traditional ACID transactions, is indeed not achievable with the requirement of high availability in the presence of partitions \cite{31}. However, database systems have a long tradition of providing weaker isolation and consistency guarantees \cite{4, 13, 43}. Due to their concurrency and overall performance benefits, weak isolation models are widely employed, overwhelmingly as the default setting in today’s traditional “ACID” and up-and-coming “NewSQL” databases and often as the maximum guarantee offered (Section 2.3). While weak isolation levels do not provide serializability for general-purpose transactions, they are apparently strong enough to deliver acceptable behavior to many application programmers. As they are stronger than the semantics of many distributed data platforms, this led to our recent proposal \cite{9} to offer \emph{Highly Available Transactions (HATs)}: general transactions with semantics similar to weak isolation databases, in ways that remain available in the face of partitions. We now build on \cite{9} by determining the partition-availability status of a wide range of previously identified isolation levels and other consistency conditions.

The relationship of the CAP Theorem and ACID semantics has been poorly understood. In the DB community, weak isolation is well studied in the single-server context from which it originated \cite{4, 13, 43} and many papers offer techniques for providing global serializability or snapshot isolation \cite{14,  30, 65; also cite several SI papers from PC members (Kemme, Elnikety, Salem, Daudgee)}. The distributed computing, programming language, and parallel hardware literature has produced many weak data consistency models for single replicated objects, or ways to build fully isolated transactions \cite{26, 28, also 45 (Herlihy-Shavit)}. Little attention has been given to weak isolation models on replicas of multiple items.

The contributions of this paper fill the gap between, on the one hand, the plethora of previously proposed isolation and consistency models, and, on the other hand, the goal of highly available systems. We introduce a hierarchy of consistency models; in doing so, we unify previous work on ACID properties \cite{4}, session guarantees \cite{64}, and traditional distributed “register” semantics \cite{45}. We rigorously taxonomize the availability characteristics of these consistency models: we determine which can be offered as Highly Available Transactions (HATs). In doing so, we argue that many implementations that provide these semantics are not partition-available, but that often the unavailability is not inherent to their semantic guarantees. Our investigation shows, somewhat surprisingly, that besides serializability, only fairly strong models like Snapshot Isolation (SI) and Repeatable Reads (RR) are \emph{inherently} unavailable, stemming from their requirement to detect conflict between concurrent operations as needed for preventing Lost Updates or Write Skew phenomena. In contrast, Read Committed isolation can be provided in a HAT system. We show that many of the weaker data consistency models from distributed systems can be implemented in a highly available manner as well, in a slightly different definition with clients which stick to (i.e. have affinity with) one server (something which is implicitly assumed in much of the previous work on distributed systems, and is sometimes reasonable in practice).

This taxonomy allows us to determine that a wide range of semantic guarantees can be delivered with availability in face of partitions, but which guarantees are worthwhile in practice? We attempt to objectively study the virtues and limitations of both classic and HAT systems by surveying practitioner accounts and research literature, performing experimental analyses on modern cloud infrastructure, and analyzing representative applications for their semantic requirements. While our results are not definitive, they suggest that HATs offer a one to three order of magnitude latency decrease compared to traditional distributed serializability protocols, and they can provide acceptable semantics for a wide range of programs, especially those with monotonic logic and commutative updates \cite{6, 24, 61}. HAT systems can also enforce arbitrary foreign key constraints on multi-item updates and sometimes provide limited uniqueness guarantees. However, particularly for programs with non-monotonic logic, HATs may fall short, requiring sometimes-unavailable mechanisms that are more coordination-intensive. Overall, this paper clarifies the benefits  Highly Available Transactions can offer and the restrictions they place on applications.
