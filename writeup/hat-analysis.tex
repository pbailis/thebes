
\section{Highly Available Transactions}
\label{sec:hats}

HAT systems provide transactions with transactional availability and
either high availability or sticky high availability. They offer
substantial latency and availability benefits compared to traditional
distributed databases, yet they cannot achieve all the traditional
semantics. In this section, we delineate ACID, distributed
consistency, and session consistency levels which can be achieved with
high availability (transactional atomicity, variants of Repeatable
Read isolation, and many session guarantees), those with sticky high
availability (read your writes, PRAM and causal consistency) and the
properties which cannot be provided in a HAT system (those preventing
Lost Update and Write Skew, or with recency).  We present a full
summary of these results in Section~\ref{sec:hat-summary}.

As Brewer states, ``systems and database communities are separate but
overlapping (with distinct vocabulary)''~\cite{brewer-slides}. With
this challenge in mind, when possible, we build on existing properties
and definitions from the database and distributed systems literature,
providing a brief, informal explanation and example for each
guarantee. The database isolation guarantees require particular care,
since different DBMSs often use the same terminology for different
mechanisms and may provide additional guarantees in addition to our
implementation-agnostic definitions.  We draw largely on Atul Adya's
dissertation~\cite{adya} and somewhat on its predecessor work: the
ANSI SQL specification~\cite{ansi-sql} and Berenson et al.'s
subsequent 1995 critique~\cite{ansicritique}. We provide a set of
formal definitions, semantics, proofs and observations in our extended
Technical Report and opt for a more informal presentation in this
paper~\cite{hat-tr}.

\subsection{Achievable HAT Semantics}

To begin, we present well-known semantics that can be achieved in HAT
systems. We offer proof-of-concept highly available algorithms but our
goal is \textit{not} to provide optimal or even efficient
implementations. These guarantees are fairly straightforward and have
been introduced---albeit with greater brevity and discussion
omitted---in a preliminary workshop paper~\cite{hat-hotos}. In our
examples, we exclusively consider read and write operations. We denote
a write of value $v$ to data item $d$ as $w_d(v)$ and a read from data
item $d$ returning $v$ as $r_d(v)$ and assume that all data items have
the null value, $\bot$, at database initialization. Unless otherwise
specified, all example transactions commit.

\subsubsection{ACID Isolation Guarantees}

To begin, \textbf{Read Uncommitted} isolation is captured by Adya as
PL-1,requiring that each transaction's writes are ordered consistently
according to a single total order on transactions. This prohibits
Adya's phenomenon $G0$, also called ``Dirty Writes''~\cite{adya}. If
two transactions write to the same set of data items, then the final
database state cannot contain the ``earlier'' transaction's writes to
the data items. For example, in the below example, $T_3$ should
\emph{eventually} only read $a=b=1$ or $a=b=2$ but not $a=2, b=1$ or
$a=1, b=2$:
\begin{align*}
\small
T_1 &: w_x(1)~w_y(1)
\\T_2 &: w_x(2)~w_y(2)
\\T_3 &: r_x(a)~r_y(b)\\[-2em]
\end{align*}
All later properties will strengthen PL-1.

Unlike the total order required by serializability, the order in PL-1
does not constrain the values seen in by a transaction's read
operations except once the database has reached a ``final
state.'' Read Uncommitted is easily achieved via applying the same
logical timestamp to each update in a transaction and applying a
``last writer wins'' conflict reconciliation policy at each replica.

\textbf{Read Committed} isolation is particularly important in
practice as it is the default of many DBMSs. Implementations differ,
with some based on long-duration exclusive locks and short-duration
read locks~\cite{gray-isolation} and others based on multiple
versions. The implementations typically have recency and monotonicity
properties beyond the simple meaning of the name, which is what is
expressed in the implementation-agnostic definition: under Read
Committed, transactions should do not access uncommitted or
intermediate versions of data items. This prohibits both ``Dirty
Writes'', as above, and also ``Dirty Reads'' phenomena.  This
isolation is Adya's PL-2, and formalised by prohibiting Adya's $G1a-c$
(or ANSI's $P1$, or ``broad'' $P1$ (2.2) from Berenson et al.). For
instance, in the example below, $T_3$ should never see $a=1$, and, if
$T_2$ aborts, $T_3$ should never read $a=3$:
\vspace{-.5em}
\begin{align*}
\small
T_1 &: w_x(1)~w_x(2)
\\T_2 &: w_x(3)\\
T_3 &: r_x(a)\\[-2em]
\end{align*}
It is fairly easy for a HAT system to prevent ``Dirty Reads'': if each
transaction never writes uncommitted data to the database, then
transactions will never read each others' dirty data. As a simple
solution, clients can buffer their writes until they commit, or,
alternatively, can send them to servers, who will not deliver their
value to other readers until notified that the writes have been
committed. This implementation does not provide recency or
monotonicity guarantees but satisfies the implementation-agnostic
definition.

``Repeatable Read'' isolation is a confusing property. Some IBM
products use the term for fully serializable
isolation~\cite{hat-hotos}. Gray~\cite{gray-isolation}, Berenson et
al.~\cite{ansicritique}, and Adya's PL-2.99~\cite{adya} all interpret
Repeatable Read as providing serializability for all operations except
for predicate-based reads (and so Repeatable Read is identical to
serializability in a key-value store without predicate-based
access). In this model, the \textit{Phantom Problem}, whereby two
successive predicate-based reads return different
data~\cite{gray-isolation}, is the only kind of non-serializable
behavior allowed. When referring to ``Repeatable Read,'' we will
follow these definitions, which, as we will soon show, are for a
property that can be offered in a highly available way.

However, As Berenson et al.~\cite{ansicritique} discuss, the ANSI SQL
specification allows many additional behaviors under the term
Repeatable Read isolation.  \textbf{ANSI Repeatable Read} requires
that, along with respecting Read Committed isolation, each transaction
will only read one version of each data item that it did not itself
produce (preventing ``Fuzzy Read,'' or P2). In the example below,
$T_3$ must read $a=1$:
\begin{align*}
\small
T_1 &: w_x(1)
\\T_2 &: w_x(2)
\\T_3 &: r_x(1)~r_x(a)
\end{align*}
This is a literal interpretation of the phrase ``Repeatable Read'':
unless a transaction modifies a given data item, the observable value
of the data item should not change during the transaction. By itself,
this property is extremely weak---we can always read $\bot$ for each
data item---and easily achieved in a HAT system by caching the values
read.

Between our Repeatable Read (PL-2.99) and the ANSI definition, is a
concept we will call \textbf{Item Cut Isolation}: that all the
transaction's reads should see values from a non-changing consistent
cut or snapshot over the data items. It is possible to satisfy Item
Cut Isolation with high availability by using multi-versioning on each
replica and ensuring that each of a transaction's reads return an
appropriately chosen version (e.g., identified by vector clock).

A stronger achievable property asks that a consistent cut spans both a
transaction's predicate reads (e.g., \texttt{SELECT WHERE}) as well as
its item reads.  We call this \textit{Predicate Cut
  Isolation}\footnote{Oracle provides an isolation level called
  ``Statement Level Read Consistency''~\cite{adya}; this is analogous
  to Predicate Cut Isolation at the level of a single operation within
  a multi-operation transaction. We do not consider this isolation
  model here as it is subsumed by standard Snapshot Isolation and we
  believe our discussion is easily extended to incorporate it.} and it
prohibits Phantoms. Predicate Cut Isolation is also achievable in HAT
systems via similar multi-versioning as above.

\subsubsection{ACID Atomicity Guarantees}

Transactional atomicity (TA) is core to ACID guarantees. Although, at
least by the ACID acronym, it is not an ``isolation'' property,
transactional atomicity restricts the ability to view the effects of
partially completed transactions. Under transactional atomicity, once
some of the effects of a transaction $T_1$ are observed by another
transaction $T_2$, thereafter all effects of $T_1$ are observed by
$T_2$. Together with item cut isolation, TA prevents Read Skew
anomalies (Berenson et al.'s A5A~\cite{ansicritique}). As an example
of TA, because $T_2$ has read $T_1$'s write to $y$, $T_2$ must observe
$b=c=1$ (or later versions for each key):
\vspace{-.5em}
\begin{align*}
\small
T_1 &: w_x(1)~w_y(1)~w_z(1)
\\T_2 &: r_x(a)~r_y(1)~r_x(b)~r_z(c)~\\[-1.5em]
\end{align*}
$T_2$ can also observe $a=\bot$, $a=1$, or a later version of
$a$. Notably, TA requires Read Committed isolation: observing all
effects of a transaction implicitly requires observing the final
(committed) effects of a transaction as well.

Perplexingly, discussions of TA are absent from existing ones of
weak isolation. This is perhaps again due to the single-node
context in which prior work was developed: on a single server (or a
fully replicated database), TA is achievable via lightweight locking
and/or local concurrency control over data items~\cite{gstore}. In
contrast, in a distributed environment, TA over arbitrary groups of
non-colocated items is considerably more difficult to achieve with
high availability: servers need to know when all of a transaction's
updates are present on their respective replicas. However, replicas do
not need to agree on when to reveal a new value to clients, which
would require consensus; accordingly, TA only requires reliable
broadcast (with some additional client metadata) and is
achievable in HAT systems. We omit a full discussion of the algorithm
and instead refer the reader to the extended version of this
paper~\cite{hat-tr}.  
%space{.5em}

\subsubsection{Session Guarantees}

Our models have not yet considered interactions \textit{across}
transactions: we have not guaranteed any ordering or continuity
between transactions, other than that there exists some arbitrary
ordering (via Read Uncommitted). In the distributed systems
literature, many useful \textit{safety} guarantees span multiple
application actions. In particular, \textit{session guarantees} are
used to describe guarantees across transactions within a given
\textit{session}, ``an abstraction for the sequence of...operations
performed during the execution of an
application''~\cite{sessionguarantees}. Informally a session describes
a context that should persist between transactions: for example, on a
social networking site, all of a user's transactions submitted between
``log in'' and ``log out'' operations might form a session.

Several session guarantees can be made with high availability:

\vspace{.5em}\noindent\textit{{Monotonic reads}} requires that, within
a session, subsequent reads to a given object ``never return any
previous values''; reads from each item progress forward in a total
order. The ordering of reads should respect any externally observable
total ordering on transactions.

\vspace{.5em}\noindent\textit{{Monotonic writes}} requires that each
session's writes be applied to any replica in the order they were
submitted by the client. Any order on transactions should also be
consistent with any precedence that a global observer would see.

\vspace{.5em}\noindent\textit{{Writes Follow Reads}} requires that, if
a session observes an effect of transaction $T_1$ and subsequently
commits transaction $T_2$, then another session can only observe
effects of $T_2$ if it can also observe $T_1$'s effects (or later
values that supercede $T_1$'s).  Any order on transactions should
respect the reads-from order.\vspace{.5em}

The above guarantees can be achieved by forcing servers to wait to
reveal new writes until each write's respective dependencies are
fulfilled on all replicas. This mechanism effectively ensures that all
clients read from a globally agreed upon lower bound on the versions
written. This \textit{is} highly available as a client
will never block due to inability to find a server with a sufficiently
up-to-date version of a data item. However, it does not imply that
transactions will read their own writes or, in the presence of
partitions, make forward progress through the version history. The
problem is that, if a server becomes partitioned, under the highly
available model, we must handle the possibility that an unfortunate
client will be forced to issue her next requests against the
partitioned server.

The solution to this conundrum is to give up high availability in
favor of sticky availability. Sticky availability permits three
additional models, which we first define and then prove are
unachievable in a generic highly available system:

\vspace{.5em}\noindent\textit{{Read your writes}} requires
that whenever a client reads a given data item after updating it, the
read returns the updated value (or a value with a higher ID).

\vspace{.5em}\noindent\textit{{PRAM}} (Pipelined Random Access
Memory) provides the illusion of serializing each session's operations
and is the combination of monotonic reads, monotonic writes, and read
your writes~\cite{herlihy-art}.

\vspace{.5em}\noindent\textit{{Causal
    consistency}}~\cite{causalmemory} is the combination of all of the
session guarantees~\cite{sessiontocausal} (alternatively, PRAM with
writes-follow-reads) and is also referred to by Adya as PL-2L
isolation~\cite{adya}).\vspace{.5em}


Read your writes is not achievable in a highly available
system. Consider a client that executes the following two transactions
in succession:
\vspace{-.5em}
\begin{align*}
\small
T_1 &: w_x(1)
\\T_2 &: r_x(a)
\end{align*}
If the client executes $T_1$ against a server that is partitioned from
the rest of the other servers, the server must allow $T_1$ to
commit. If the client executes $T_2$ against the same (partitioned)
server, then it will be able to read its writes. However, if the
network topology shifts and the client can only contact a different
server that is partitioned from the server that executed $T_1$, then
the client will be unable to read its own writes and the system will
have to either stall indefinitely to allow the client to read her
writes (violating transactional availability) or will have to
sacrifice read your writes guarantees. However, if the client remains
sticky with the server that executed $T_1$, then we can disallow this
scenario. Accordingly, read your writes, and, by proxy, causal
consistency and PRAM require stickiness. Read your writes is ``free''
in a sticky system, while the remaining causality and PRAM guarantees
can be accomplished with the algorithms for achieving the remaining
session guarantees.

\subsubsection{Additional HAT Guarantees}

In this section, we briefly discuss additional noteworthy guarantees
achievable by HAT systems.

\vspace{0.5em}
\noindent{\textbf{Consistency}} A HAT system can make limited
consistency guarantees. It can often execute commutative and logically
monotonic~\cite{calm} operations without the risk of invalidating
 application-level integrity constraints. Our goal in
this paper is not to sketch the entire space of consistency models
that are achievable (see Section~\ref{sec:futurework}). We
specifically evaluate TPC-C transaction semantics under HAT
consistency guarantees in Section~\ref{sec:evaluation}.

\vspace{.5em}\noindent{\textbf{Durability}} A client requiring that its
transactions' effects survive $F$ server faults requires at least
$F+1$ correct nodes.

\vspace{.5em}\noindent{\textbf{Convergence}} To require that the
system propagates writes between replicas, we can require convergence,
or eventual consistency for each data item: in the absence of new
mutations to a data item, in the absence of partitions, all servers
should eventually agree on the value for each item. This is typically
accomplished by any number of anti-entropy protocols, which
periodically update neighboring servers with the latest value for each
data item~\cite{antientropy}. Establishing a final value is related to
determining a total order on transaction updates, as in Read
Uncommitted.

\subsection{Unachievable HAT Semantics}
\label{sec:unachievable-hat}

While there are infinitely many HAT models
(Section~\ref{sec:futurework}), at this point, we have largely
exhausted the range of achievable, previously defined (and useful)
semantics that are available to HAT systems. Before summarizing our
possibility results, we will present impossibility results for HATs,
also defined in terms of previously identified isolation and
consistency anomalies. Most notably, it is impossible to
prevent Lost Update or Write Skew in a HAT system.

\subsubsection{Unachievable ACID Isolation}

In this section, we demonstrate that preventing Lost Update and Write
Skew---and therefore providing Snapshot Isolation, Repeatable Read,
and one-copy serializability---inherently requires unavailability.

In the words of Berenson et al., \textit{Lost Update} occurs when one
transaction $T1$ reads a given data item, a second transaction $T2$
updates the same data item, then $T1$ modifies the data item based on
its original read of the data item, ``missing'' or ``losing'' $T2$'s
newer update. Consider a database containing only the following
transactions:
\begin{align*}
\small
T_1 &: r_x(a) w_x(a+2)
\\T_2 &: w_x(2)
\end{align*}
If $T_1$ reads $a=1$ but $T_2$'s write to $x$ precedes $T_1$'s write
operation, then the database will end up with $a=3$, a state that
could not have resulted in a serial execution due to from $T_2$'s
``Lost Update.''

It is impossible to prevent Lost Update in a highly available
environment. Consider two clients who submit the following $T_1$ and
$T_2$ on opposite sides of a network partition:
\begin{align*}
\small
T_1 &: r_x(100)~w_x(100+20=120)
\\T_2 &: r_x(100)~w_x(100+30=130)
\end{align*}
Regardless of whether $x=120$ or $x=130$ is chosen by a replica, the
database state could not have arisen serial execution of $T_1$ and
$T_2$.\footnote{In this example, we assume that, as is standard in
  modern databases, replicas accept values as they are written (i.e.,
  register semantics). This particular example could be made
  serializable via the use of commutative updates
  (Section~\ref{sec:evaluation}) but, as we show in the extended version of
  the paper~\cite{hat-tr}, the problem persists in the general case.}
To prevent this from happening, either $T_1$ or $T_2$ should not have
committed. Each client's respective server might try to detect that
another write occurred, but this requires knowing the version of the
latest write to $x$. In our example, this reduces to a requirement for
linearizability, which is, via Gilbert and Lynch's proof of the CAP
Theorem, provably unachievable with high
availabilty~\cite{gilbert-cap}.

\textbf{Write Skew} is a generalization of Lost Update to multiple
keys. It occurs when one transaction $T1$ reads a given data item $x$,
a second transaction $T2$ reads a different data item $y$, then $T1$
writes to $y$ and commits and $T2$ writes to $x$ and commits. As an
example of Write Skew, consider the following two transactions:
\begin{align*}
\small
T_1 &: r_y(0)~w_x(1)
\\T_2 &: r_x(0)~w_y(1)
\end{align*}
As Berenson et al. describe, if there was an integrity constraint
between $x$ and $y$ such that only one of $x$ or $y$ should have value
$1$ at any given time, then this write skew would violate the constraint (which is preserved in serializable executions). Write skew is a somewhat
esoteric anomaly---for example, it does not appear in
TPC-C~\cite{snapshot-serializable}---but, as a generalization of Lost
Update, it is also unavailable to HATs.

Their need to prevent Lost Update means that Consistent Read, Snapshot
Isolation, and Cursor Stability guarantees are all unavailable.
Repeatable Read (in the sense of Gray~\cite{gray-isolation}, Berenson
et al.~\cite{ansicritique}, or Adya~\cite{adya}) and One-Copy
Serializability need to prevent both Lost Update and Write Skew; this
means that they are also inherently unavailable.

\subsubsection{Unavailable Recency Guarantees}

Data storage systems make various recency guarantees on reads of data
items. As we have discussed, one of the most famous is
linearizability~\cite{herlihy-art}, which states that reads will
return the last completed write to a data item, and there are several
other (weaker) variants such as safe and regular register
semantics. When applied to transactional semantics, the combination of
one-copy serializability and linearizability is called \textit{strong
  (or strict) one-copy serializability}~\cite{adya} (e.g., Google's
Spanner~\cite{spanner}). It is also common, particularly in systems
that allow reading from masters and slaves, to provide a guarantee
such as ``read a version that is no more than five seconds out of
date'' or similar. Unfortunately, an indefinitely long partition can
force an available system to violate any recency bound, so recency
bounds are not enforceable in HAT systems.

\subsection{Summary}
\label{sec:hat-summary}

We summarize our results in Table~\ref{table:hatcompared}. A wide
range of isolation levels are achievable in a HAT systems, including
transactional atomicity, cut isolation, and several session
guarantees. With sticky availability, a system can achieve read your
writes guarantees and PRAM and causal consistency. However, many other
prominent models, such as Snapshot Isolation, One-Copy
Serializability, and Strict Serializability cannot be achieved due to
the inability to prevent Lost Update and Write Skew phenomena.

We illustrate the hierarchy of available, sticky available, and
unavailable consistency models we have discussed in
Figure~\ref{fig:hatcompared}. Many models are simultaneously
achievable, but we find several particularly compelling. If we combine
all sticky-HAT guarantees, we have transactional, causal snapshot
reads (i.e., Causal Transactional Predicate Cut Isolation). If we
combine TA and P-CI, we have transactional snapshot reads. We can
achieve RC, MR, and RYW by simply sticking clients to servers. And we
can also combine unavailable models---for example, an unavailable
system might provide PRAM and One-Copy
Serializability~\cite{daudjee-session}.

To the best of our knowledge, this is the first unification of
database ACID, distributed consistency, and session guarantee
models. Interestingly, strong one-copy serializability subsumes all
other models, while considering the (large) power set of all
compatible models (e.g., the diagram depicts 96 possible highly
available combinations) hints at the vast expanse of consistency
models found in the literature. This taxonomy  is \textit{not}
exhaustive, but we believe it lends substantial clarity into the
relationships between a large subset of the prominent ACID and
distributed consistency models. Additional read/write transaction
semantics that we have omitted should be easily classifiable based on
the available primitives and HAT-incompatible anomaly prevention we
have already discussed.

 \newcommand{\lostupdate}{$^\dagger$}
 \newcommand{\rwskew}{$^\ddagger$}
 \newcommand{\linearizable}{$^\oplus$}

\begin{table}[t!]
\begin{tabular}{| c | p{6cm} | }\hline
HA & Transactional Atomicity (TA), Read Uncommitted (RU), Read
Committed (RC), Item Cut Isolation (P-CI), Predicate Cut Isolation
(P-CI), Monotonic Reads (MR), Monotonic Writes (MW), Writes Follow
Reads (WFR)\\\hline Sticky-HA & Read Your Writes (RYW), PRAM,
Causal\\\hline Unavailable & Cursor Stability (CS)\lostupdate,
Snapshot Isolation (SI)\lostupdate, Repeatable Read
(RR)\lostupdate\rwskew, One-Copy Serializability
(1SR)\lostupdate\rwskew, Recency\linearizable, Safe\linearizable,
Regular\linearizable, Linearizability\linearizable, Strong
1SR\lostupdate\rwskew\linearizable \\\hline
\end{tabular}
\caption{Summary of highly available, sticky highly available, and
  unavailable models considered in this paper. Unavailable models are
  labeled by cause of unavailability: preventing lost
  update\lostupdate, preventing write skew\rwskew, and requiring
  recency guarantees\linearizable.}
\label{table:hatcompared}
\end{table}

\begin{figure}[t!]
\centering
\begin{tikzpicture}[scale=0.8]
  \tikzstyle{sticky}=[rectangle,draw=blue!50,fill=blue!20,thick]
  \tikzstyle{noha}=[ellipse,draw=red!50,fill=red!20,thick, inner sep=0pt,minimum size=12pt]

  \tikzstyle{every node}=[font=\small]

 \node[draw=none,fill=none] (ici) at (1.2, 0) {I-CI};
 \node[draw=none,fill=none] (pci) at (1.65, 1.2) {P-CI};
 \node[draw=none,fill=none] (rc) at (-1.2, .8) {RC};
 \node[draw=none,fill=none] (ru) at (-1.2, 0) {RU};

 \node[draw=none,fill=none] (ta) at (-.2, 1.3) {TA};

 \node[draw=none,fill=none] (mr) at (3.6, 0) {MR};
 \node[draw=none,fill=none] (mw) at (4.8, 0) {MW};
 \node[draw=none,fill=none] (wfr) at (2.4,0) {WFR};
 \node at (6.1,0) [sticky] (ryw) {RYW};

 \node[noha](recency) at (7.7, 0) {recency};
 \node[noha](safe) at (7.7, 1) {safe};
 \node[noha](regular) at (7.7, 2) {regular};
 \node[noha](linearizable) at (7.7, 3) {linearizable};
 \node at (4.8, 2) [sticky] (causal) {causal};
 \node at (4.8, 1) [sticky] (pram) {PRAM};
 \node[noha] (cs) at (-1.2, 1.8) {CS};
 \node[noha] (rr) at (-.2, 2.7) {RR};
 \node[noha] (si) at (2.2, 2.4) {SI};
 \node[noha] (1sr) at (1.2, 3.2) {1SR};
 \node[noha] (ssr) at (3.85, 3.6) {Strong-1SR};

 \draw [->, red] (recency) -- (safe);
 \draw [->, red] (safe) -- (regular);
 \draw [->, red] (regular) -- (linearizable);
 \draw [->, red] (linearizable) -- (ssr);
 \draw [->, red] (1sr) -- (ssr);
 
 \draw [->] (ru) -- (rc);
 \draw [->] (rc) -- (ta);
 \draw [->] (ici) -- (pci);

 \draw [->, blue] (mr) -- (pram);
 \draw [->, blue] (mw) -- (pram);
 \draw [->, blue] (wfr) -- (causal);
 \draw [->, blue] (ryw) -- (pram);
 \draw [->, blue] (pram) -- (causal);

 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (ru) -- (mr);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (rc) -- (ta);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (ici) -- (ta);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (pci) -- (ta);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (rc) -- (mr);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (pci) -- (mr);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (ici) -- (mr);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (ta) -- (ru);
 %\draw[snake=coil, blue, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (ru) -- (causal);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (mr) -- (mw);
 %\draw[snake=coil, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (wfr) -- (mw);
 %\draw[snake=coil, blue, segment aspect=0, segment amplitude=.75pt, segment length=2pt] (wfr) -- (ryw);

 \draw [->, red] (rc) -- (cs);
 \draw [->, red] (cs) -- (rr);
 \draw [->, red] (pci) -- (si);
 \draw [->, red] (ici) -- (rr);
 \draw [->, red] (rr) -- (1sr);
 \draw [->, red] (si) -- (1sr);
 \draw [->, red] (ta) -- (si);
 \draw [->, red] (ta) -- (rr);
 \draw [->, red] (causal) -- (linearizable);
 \draw [->, red] (ryw) -- (safe);

\end{tikzpicture}
\label{fig:hat-order}
\caption{HAT, sticky HAT (in boxes), and unavailable models (circled)
  from Table~\protect\ref{table:hatcompared} compared
  graphically. Directed edges represent ordering by model
  strength. Models that do not share a common ancestor can be
  simultaneously achieved, and the resulting availability is that of
  the weakest available model in the combination.}
\label{fig:hatcompared}
\end{figure}\vspace{-1em}


\subsection{Discussion}
\label{sec:discussion}

In this section, we discuss several subtleties in our results,
specifically addressing model composition, transactional atomicity
versus linearizability, and stickiness requirements.

\vspace{.5em}\noindent\textbf{Model Composition} Choosing between
combinations of compatible guarantees requires care. Consider the
following transactions:
\begin{align*}
\small
T_1 &: w_x(1)~w_y(1)
\\T_2 &: w_x(2)~w_y(2)
\\T_3 &: r_x(a)~r_y(b)
\end{align*}
If we want to guarantee both cut isolation and transactional atomicity
and the system only executes $T_1$, $T_2$, and $T_3$, then $T_3$ needs
to read $a=b=\bot$, $a=b=1$, or $a=b=2$. This means that either the
implementation should frequently return $\bot$ (definitely undesirable
and possibly non-convergent), keep multiple versions of each data item
(necessitating potentially complicated distributed garbage
collection), or use pre-declared read sets to fetch a consistent cut
of keys before each transaction begins to execute. Using client-side
caching can alleviate some of these challenges~\cite{bolton, swift},
but then the system becomes sticky high available.

Composition cost may also vary by combination. For instance, Charron-Bost
 proved that, to capture causality between $N$ communicating
processes, standard vector-based approaches face an upper bound of
$O(N)$ storage per write~\cite{charron-bost}. This means that, with
$100K$ clients, each write might be accompanied by $100K$ timestamps
per vector. This is difficult to scale. By compromising on
availability (e.g., treating a datacenter as a linearizable cluster),
this overhead can be reduced~\cite{eiger}, but it is much
cheaper to provide, say, read your writes, than full causal
consistency.

\vspace{.5em}\noindent\textbf{Linearizability and Transactional
  Atomicity} The relationship between linearizability and
transactional atomicity is non-obvious. Transactional atomicity
dictates that writes to multiple keys across multiple servers are made
visible to readers all at once, while linearizability dictates that
writes to a single key on multiple servers are made visible to all
readers at once---what is different? First, in linearizable (and safe
and regular) systems, writes are made visible to all clients
\textit{immediately} after they finish. With transactional atomicity,
there is no recency guarantee. Second, in linearizabile systems, all
clients see all writes at the same time. With transactional atomicity,
clients may see writes at different times depending on which replicas
they contact. We are not aware of an analogous model in the
distributed systems literature. Accordingly, despite apparent
similarities, transactional atomicity is incomparable with and much
cheaper (by availability standards) than linearizability.

\vspace{.5em}\noindent\textbf{Visibility and Stickiness} Sticky
availability can result in much better write \textit{visibility}:
clients will be able to safely read writes more quickly in a sticky
available system. In the model we discussed, it is possible to achieve
several properties like monotonic reads in a highly available system
by waiting to reveal a write until all servers have seen it and its
relevant dependencies. However, this incurs severe visibility
penalties---new writes will not become visible to clients in the
presence of partitions. A client that does not want to guarantee
read-your-writes (due to the sticky availability requirement) may
still wish to read other clients' writes with timeliness.
