
\section{Analysis}
\label{sec:evaluation}

With a firm understanding of which of several ACID and distributed
consistency properties are available and not, we perform analysis of
their implications for existing algorithms, applications, and
deployments. Specifically:

\begin{enumerate}
\item We revisit traditional database concurrency control with a focus
  on coordination costs and on high availability.
\item We examine the properties required by a realistic OLTP
  application patterned on TPC-C.
\item We perform a brief experimental evaluation of HAT versus non-HAT
  properties on public cloud infrastructure.
\end{enumerate}

\subsection{Existing Algorithms}

As we have discussed, many existing database transaction and
concurrency control algorithms are not designed for high
availability. These algorithms often presume a single-server
deployment or the requirement for serializability. As a consequence,
traditional transaction processing systems are not well-optimized for
a HAT context.

We begin by considering several existing algorithms that provide
serializability but are not highly available. In summary, all
algorithms in this class require at least one round trip time (RTT)
before committing.

\begin{itemize}
\item \textbf{Two-phase locking} (ignoring deadlocks) requires $T$
  lock operations and 1 unlock operation for a transaction of length
  $T$. If all items are located on a single master server, this
  requires one RTT (for requests originating from servers other than
  the master). If items are located on $S$ ($S \leq T$) different
  servers, two-phase locking requires, at minimum, $2(S-1)$ RTTs---one
  for lock and another for unlock.

\item \textbf{Optimistic concurrency control} allows reads from any
  server but transactions must be checked by a scheduler before
  commit. With one scheduler per database, this requires one RTT for
  concurrency control. If schedulers are sharded by database
  partition, a multi-partition transaction may require contacting
  several different schedulers and, possibly, an atomic commit
  protocol, which becomes substantially more expensive.

\item \textbf{Deterministic transaction scheduling} is effecitvely the
  inverse of optimistic concurrency control: a scheduler first orders
  the transactions, then sends them to database replicas for in-order
  execution. These techniques, pioneered in the context of totally
  ordered atomic broadcast systems, have recently seen increased
  attention and effectively require communication overhead similar to
  optimistic concurrency control.

\item\textbf{Multiversion concurrency control} allows readers to read
  older versions of data items but, like OCC, must eventually be
  checked for write-write conflicts, requiring a scheduler.

\end{itemize}

There are several mechanisms that do not provide serializability (and
often provide HAT semantics) but which are not available:

\begin{itemize}
\item \textbf{Lock-based protocols} such as those used to provide weak
  isolation in Gray's original paper require at least one RTT to the a
  lock server (or, alternatively, a majority quorum). In the presence
  of failure, distributed locking can be challenging.
\item The \textbf{MDCC} commit protocol uses a Paxos variant and escrow
  transactions to provide Repeatable Read isolation with 1-2 RTTs. (TODO: CHECK)
\item \textbf{Parallel Snapshot Isolation} as developed by the Walter
  system provides (unavailable) snapshot isolation variant and, even
  when writes commute, requires 1 RTT to enforce read
  recency. However, PSI without recency requirements could be made
  highly available.
\item \textbf{Eiger} provides read-only and write-only transactions
  with item cut isolation and causal consistency. It relies on sticky
  high availability and groups within a datacenter with linearizable
  clusters. In the presence of server failure during write
  transactions, reads and writes may become unavailable. \textbf{COPS}
  provides similar semantics for read-only transactions but does not
  suffer from unavailability as it does not have a coordinator.
\item \textbf{Chan and Gray read-only transactions} use a similar
  algorithm to Eiger to provide read-only transactions with item cut
  isolation and causal consistency but coordinate on reads instead of
  writes.
\item \textbf{Bolt-on Causal Consistency} and \textbf{Swift} can
  provide read-only and write-only transactions with item cut
  isolation and causal consistency with sticky high availability and
  both rely on client-side caching.
\item \textbf{Bayou} provides several session guarantees but, without
  client-side caching, actually faces unavailability in the presence
  of failure. (TODO: CHECK)
\item \textbf{Brantner's S3 Database} uses caching to provide several
  guarantees such as XX and YY but is unavailable during failures
  (TODO: CHECK).
\end{itemize}

\subsection{Application Requirements}

2.) We ran YCSB on EC2 (and maybe TPC-C if we have time) with a few models:
	- Eventual Consistency
	- Eventual consistency with a "master" for updates--simulates the lower bound on a non-HAT system.
	- Transactional Atomicity and Read Committed
	
	-This is going to look a lot like the ping tests: much higher latency for "non-HATs."
	-Our Naive 2PL implementation bottlenecks extremely quickly.
	-On, say, 5 servers, can get hundreds of thousands of TPS

	-Not meant as an exhaustive study, but validates our intuitions. Coordination costs of non-HAT systems are unaccounted for, will only go up, and we haven't even talked about availability.

\subsection{Experimental Costs}



