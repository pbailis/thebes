
\section{High Availability}
\label{sec:availability}

To understand which guarantees can be provided with high availability,
we must first define what high availability means. In this section, we
will formulate a model that captures a range of availability models,
including high availability, availability with stickiness, and
transactional availability.

Informally, highly available algorithms ensure ``always on'' operation
and, as a side effect, guarantee low latency. If users of a highly
available system are able to contact a (set of) server(s) in a system,
they are guaranteed a response; this means servers will not need to
synchronously communicate with others. If servers are partitioned from one
another, they do not need to stall in order to provide clients a
``safe'' response to operations. This lack of fast-path coordination
also means that a highly available system also provides low
latency~\cite{abadi-pacelc}; in a wide-area setting, clients of a
highly available system need not wait for cross-datacenter
communication. To properly describe whether a \textit{transactional}
system is highly available, we need to describe what servers a client
must contact as well as what kinds of responses a server can provide,
especially given the possibility of aborts.

\subsection{Replica Availability}

Traditionally, a system provides {\textbf{high availability}} if every
user that can contact a correct (non-failing) server eventually
receives a response from that server, even in the presence of
arbitrary, indefinitely long network partitions between
servers~\cite{gilbert-cap}.\footnote{Under this definition from the
  distributed systems literuter, systems that require a majority of
  servers to be online is not available. Similarly, a system which
  ensures that clients receive a response with high (but not perfect)
  probability is not available. This is a stringent but matches the
  assumptions made in the CAP Theorem~\cite{gilbert-cap} and
  guarantees low latency~\cite{abadi-pacelc}.} As in a standard
distributed database, designated servers might perform operations for
different data items; a server that can handle an operation for a
given data item is called a \textit{replica} for that
item.\footnote{There is a further distinction between a \textit{fully
    replicated} system, in which all servers are replicas for all data
  items, and a \textit{partially replicated} system, in which at least
  one server acts as a replica for only a subset of all data
  items. For generality, and, for applicability to many modern
  ``sharded'' or ``partitioned'' data storage systems~\cite{ bigtable,
    pnuts, spanner, dynamo, hstore}, we consider partially replicated
  systems.}

\subsection{Sticky Availability}

In addition to high availability, which allows operations on any
replica, distributed algorithms often assume a model in which clients
always contact the same logical (sets of) replica(s) across subsequent
operations. As we will discuss in Section~\ref{sec:hats}, clients can
ensure continuity between operations (e.g., reading their prior
updates to a data item) by maintaining affinity or ``stickiness'' with
a server or set of servers~\cite{vogels-defs}. In a fully-replicated
system, where all servers are replicas for all data items, stickiness
is simple: a client can maintain stickiness by contacting the same
server for each of its requests. However, to stay ``sticky'' in a
partially-replicated system, where servers are replicas for subsets of
the set of data items (which we consider in this paper), a client must
maintain stickiness with a single \textit{logical} server that may
consist of multiple physical servers.. We say that a system provides
\textbf{sticky availability} if, whenever a client's operation on an
item is executed against a logical server that has observed all of its
prior operations, it eventually receives a response, even in the
presence of indefinitely long partitions. A client may choose to
become sticky available by acting as a server itself; for example, a
client might cache its reads and writes~\cite{bolton,
  sessionguarantees, swift}. Any guarantee achievable in a highly
available system is achievable in a sticky high availability system
but not vice-versa.

%% \begin{figure}
%% \centering
%% \begin{tikzpicture}[scale=0.8]
%%   \tikzstyle{every node}=[font=\small]
%%  \node[draw=none,fill=none] (1) at (0,0) {$1$-availability (high availability)}; 
%%  \node[draw=none,fill=none] (2) at (0,1) {$2$-availability}; 
%%  \node[draw=none,fill=none] (m-1) at (0, 2) {\ldots}; 
%%  \node[draw=none,fill=none] (m) at (0, 3) {majority availability}; 
%%  \node[draw=none,fill=none] (m+1) at (0, 4) {\ldots}; 
%%  \node[draw=none,fill=none] (n) at (0, 5) {$N$-availability}; 
%%  \node[draw=none,fill=none] (1s) at (4, 1.5) {$1$-sticky availability};
%%  \node[draw=none,fill=none] (2s) at (4, 2.5) {$2$-sticky availability};
%%  \node[draw=none,fill=none] (n2s) at (4, 3.5) {\ldots};
%%  \node[draw=none,fill=none] (n1s) at (4, 4.5) {$(N$$-$$1)$-sticky availability};

%%  \draw [->] (1) -- (2);
%%  \draw [->] (2) -- (m-1);
%%  \draw [->] (m-1) -- (m);
%%  \draw [->] (m) -- (m+1);
%%  \draw [->] (m+1) -- (n);
%%  \draw [->] (1) -- (1s);
%%  \draw [->] (1s) -- (m);
%%  \draw [->] (2s) -- (m+1);
%%  \draw [->] (1s) -- (2s);
%%  \draw [->] (2) -- (2s);
%%  \draw [->] (2s) -- (n2s);
%%  \draw [->] (n2s) -- (n1s);
%%  \draw [->] (n1s) -- (n);


%% \end{tikzpicture}
%% \caption{Hierarchy of replica availability levels for $N>3$ servers.}
%% \label{fig:availability-order}
%% \end{figure}

%% We show a hierarchy of replica availability levels in
%% Figure~\ref{fig:availability-order}. $K$-sticky availability subsumes
%% $K$-availability, but $K$-sticky availability is incomparable with
%% $(K+1)$-availability. $N$-sticky availability is equivalent to
%% $N$-availability, while majority availability subsumes $1$-sticky
%% availability. More generally, $\lceil \frac{N}{2} \rceil$$+$$K$$-$$1$
%% availability subsumes $K$-sticky availability. We have omitted
%% discussion of operation-specific availability levels (e.g.,
%% $N$-availability for writes and $1$-availability for reads in a
%% write-all, read-one data store), system membership changes, or
%% heterogeneous replicas (e.g., servers in a local and remote
%% datacenters) but believe there are several avenues for further
%% taxonomization.

\subsection{Transactional Availability}

Until now, we have considered single-object, single-operation
availability. This is standard in the distributed systems literature
(e.g., distributed register models such as linearizability all concern
single objects~\cite{herlihy-art}), yet the database literature
largely focuses on transactions: groups of multiple operations over
multiple objects. Accordingly, by itself, traditional definitions of
high availability are insufficient to describe availability guarantees
for transactions. Additionally, given the choice of \textit{commit}
and \textit{abort} responses---which signal transaction success or
failure to a client---we must take care in defining transactional
availability.

If a client wishes to execute a transaction that performs operations
on multiple data items, then the client must be able to contact and
receive a response from at least one replica for each data item. We
say that a transaction has \textbf{replica availability} if it can
contact at least one replica for every item it attempts to
access. This may result in ``lower availability'' than a
non-transactional requirement. Additionally, given the possibility of
system-initiated aborts, we need to ensure useful forward progress: a
system can trivially guarantee clients a response by always aborting
all transactions. However, this is an unsatisfactory system because
nothing good (transaction commit) ever happens; we should require a
\textit{liveness} property~\cite{transaction-liveness}. We cannot
guarantee that every transaction will commit---transactions may choose
to abort themselves---but we need to make sure that the system will
not indefinitely abort transactions on its own volition. We call a
transaction abort due to a transaction's own choosing (e.g., as an
operation of the transaction itself or due to a would-be violation of a declared integrity constraint) an \textit{internal abort} and an
abort due to system implementation or operation an \textit{external
  abort}. We say that a system provides \textbf{transactional
  availability} if, given replica availability for every data item in
a transaction, the transaction eventually commits (possibly after
multiple client retries) or internally aborts~\cite{hat-hotos}.

