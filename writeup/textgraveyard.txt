

\vspace{.5em}\noindent\textbf{Commutativity and Monotonicity} As
evidenced by the CALM Theorem~\cite{calm} and by Commutative and
Replicated Data Types~\cite{crdt}, if updates commute, then they can
often be safely performed in different orders at different
replicas. Accordingly, as long as all writes are delivered to all
replicas, then a system executing monotonic logic may not suffer from
application-level consistency anomalies as a result of Lost Update or
Write Skew anomalies. However, applications with non-monotone state
mutation will not, in general, be able to maintain application-level
consistency constraints with HATs. A in eds hin Moreover, applications
requiring visibility bounds should opt for unavailability.


\subsection{Additional Discussion}
\label{sec:discussion}

In this section, we discuss several subtleties in our results,
specifically addressing model composition, read atomicity
versus linearizability, and benefits of stickiness.

\vspace{.5em}\noindent\textbf{Model Composition} Choosing between
combinations of compatible guarantees requires care. Consider the
following transactions:
\begin{align*}
\small\vspace{-1em}
T_1 &: w_x(1)~w_y(1)
\\T_2 &: w_x(2)~w_y(2)
\\T_3 &: r_x(a)~r_y(b)\vspace{-1em}
\end{align*}
If we want to guarantee both cut isolation and MAV isolation and the
system only executes $T_1$, $T_2$, and $T_3$, then $T_3$ needs to read
$a=b=\bot$, $a=b=1$, or $a=b=2$. This means that either the
implementation should frequently return $\bot$ (definitely undesirable
and possibly non-convergent), keep multiple versions of each data item
(necessitating potentially complicated distributed garbage
collection), or use pre-declared read sets to fetch a consistent cut
of keys before each transaction begins to execute. Using client-side
caching can alleviate some of these challenges~\cite{bolton, swift} at
the expense of requiring sticky availability. Study of the
architectural interaction and overheads of various combinations is a
promising area for future work.

\vspace{.5em}\noindent\textbf{Linearizability and Read
  Atomicity} The relationship between linearizability and
MAV is non-obvious. MAV dictates that writes to
multiple keys across multiple servers are made visible to readers all
at once, while linearizability dictates that writes to a single key on
multiple servers are made visible to all readers at once---what is
different? First, in linearizable (and safe and regular) systems,
writes are made visible to clients \textit{immediately} after they
finish. With MAV, there is no recency
guarantee. Second, in linearizable systems, all clients see all writes
at the same time. With MAV as defined here, clients may see writes at
different times depending on which replicas they contact. We are not
aware of an analogous model in the distributed systems
literature. Accordingly, despite apparent similarities, MAV is
incomparable with and less coordination intensive (by availability
measures) than linearizability.

\vspace{.5em}\noindent\textbf{Visibility and Stickiness} Sticky
availability can improve write \textit{visibility}: clients will be
able to safely read writes more quickly in a sticky available
system. In the model we discussed, it is possible to achieve several
properties like monotonic reads in a highly available system by
waiting to reveal a write until all servers have seen it and its
relevant dependencies. However, this incurs severe visibility
penalties---new writes will not become visible to clients in the
presence of partitions. A client that does not want to guarantee
read-your-writes (due to the sticky availability requirement) may
still wish to read other clients' writes with timeliness.




 However, several
studies rigorously classify \textit{non-HAT} semantics: Wisemann et
al. have proposed a three parameter classification for one-copy
serializable database systems, performing a more extensive
classification than our overview in Section~\ref{sec:evaluation},
including eager database replication
techniques~\cite{kemme-classification} and distributed mechanisms for
achieving one-copy serializability~\cite{wisemann-survey}.

Causal Serializability offers a similar model
(with unavailable implementation): causal consistency with a variant
of Read Uncommitted between transactions that write to the same data
item~\cite{raynal-causal}. 

: servers need to ensure that,
regardless of replica selection, all of a client's accesses will read
a sufficiently up-to-date/``consistent'' set of data items. However,
replicas do not need to agree on when to choose to reveal sets of
values to clients, which would require consensus. Instead, as we see
below, RA only requires the equivalent of reliable broadcast (with
some additional client metadata) and is achievable in HAT systems.

However, one key property with RA is that it do not dictate when
writes become visible; accordingly, the algorithm is highly
available. We can optimize write visibility via sticky availability by
sticking clients are with disjoint groups of servers: once all of a
transaction's writes are pending stable within a group of servers,
writes can be made visible (as opposed to once they are pending stable
with respect to all servers). For example, in a multi-datacenter
setting, all clients and servers within a datacenter may form a sticky
group.



In our non-sticky TA algorithm, clients buffer their writes until
commit, sending the final write to each data item to each respective
server. Along with each write, clients attach a the transaction ID and
a list of all data items written to in the transaction, $L_v$. Upon
receiving a new write to item $d$, a server places the write into a
\texttt{pending} queue and notifies all other servers responsible for
a data item in $L_v$ that it has received a write to $d$ with the
respective transaction ID. Once a server receives acknowledgments with
appropriate transaction ID for all items in $L_v$, it moves the write
from \texttt{pending} to the \texttt{stable} database (which applies
the writes according to highest-ID-wins). Accordingly, all writes that
should be made atomic with a write in \texttt{stable} are guaranteed
to be present on their respective servers, either in \texttt{pending}
or \texttt{stable}. Given the possibility of internal aborts, writes
to \texttt{pending} may require 2 RTTs: one to check constraints and
one to execute the above (but these checks \textit{cannot} cause other
transactions to block, as would be the case in a two-phase
\textit{commit} protocol).

For reads, each client tracks which values it should read. It
maintains a mapping (vector) from data items to transaction IDs. Upon
transaction start, the client clears its mapping, and, when it
performs a read from a data item, it sends the server its current ID
for the item. If the client does not supply an ID, the server returns
the latest value from \texttt{stable}. If the ID is non-empty, the
server either returns the matching value from \texttt{pending} or a
value with higher ID from \texttt{pending}---along with $L_v$ for the
write. When the client receives a response, it updates its local
vector with $L_v$. Accordingly, even if transaction's writes to two
keys $x$ and $y$ are present on the replica for $x$'s \texttt{stable}
and the replica for $y$'s \texttt{pending}, a client's reads from $x$
then $y$ will return a transactionally atomic pair of values because
the replica for $y$ will know to check \texttt{pending}.

As Figure~\ref{fig:wan-exp} shows, within a single datacenter, a
mastered implementation achieves approximately double the latency and
slightly over half of the throughput of a HAT implementation. This is
because, given two replicas for each key, the mastered implementation
serves requests from only one. The mastered implementation still
achieves $19,797$ transactions per second---over 6,000 per
master---and is only $15.56$ms slower at peak compared to eventual
consistency. However, eventual consistency and HAT models achieve
substantially higher throughput--$37,575$ and $36,178$ transactions
per second, respectively--and lower latency---$48.3\%$ and $47.2\%$
respectively. This difference is unsurprising because, in these weaker
models, all servers can serve both reads and writes, effectively
doubling the capacity of the system. The weaker models still propagate
new values between replicas, but this process is asynchronous and,
aside from consuming disk I/O and network bandwidth, does not
substantially impact clients. As expected, HAT models perform
similarly to eventual consistency: our Read Committed implementation
buffers client writes and adds no additional server-side overhead,
while TA requires additional metadata with each write but has less
than 5\% performance impact compared to eventual consistency.

In comparison, over multiple datacenters, the cost of coordination
increases. The HAT and eventual consistency implementations continue
to enjoy local RTTs only, and, with the exception of a slight
performance degradation in TA---which we believe is attributable to
Java garbage collection overheads in TA's inbound anti-entropy
buffers---performance remains unchanged. However, each YCSB update to
a remote replica ($\frac{2}{3}$ in one datacenter, $\frac{1}{3}$ in
the other) of requiring a remote RTT between Virginia and Oregon (or
vice-versa) to reach the master. This leads to a latency increase of
around $166$ms ($746\%$) per transaction compared to a
single-datacenter deployment. In order to attain reasonable throughput
for the mastered deployment, we had to greatly increase the number of
concurrent clients accessing the database, and we found that threading
and socket overheads quickly overwhelmed the database server. Over a
wide-area network, the increased cost of RTTs dramatically affects
system efficiency.



\footnote{Oracle provides an isolation level called
  ``Statement Level Read Consistency''~\cite{adya}; this is analogous
  to Predicate Cut Isolation at the level of a single operation within
  a multi-operation transaction. We do not consider this isolation
  model here as it is subsumed by standard Snapshot Isolation; we
  believe our discussion is easily extended to incorporate it.}

Deutsch concludes his list of ``Fallacies'' by noting that ignoring
network failures and latency such as those in
Section~\ref{sec:motivation} can ``cause big trouble and painful
learning experiences''~\cite{fallacies-deutsch}. However, systems
designers must make fundamental trade-offs between latency, system
behavior during partitions, and achievable semantics. In this section,
we briefly discuss known semantic limits for systems wishing to
maintain high availability and their impact on modern database
systems. We show that many database systems operate under weak model
whose availability characteristics are unknown, motivating further
study of these models in a highly available context in the remainder
of this paper.

One of the most popularly celebrated impossibility results in
distributed systems is Brewer's CAP Theorem~\cite{brewer-slides},
which, as formally proven by Gilbert and Lynch~\cite{gilbert-cap},
states that it is impossible to maintain linearizability , or the
ability to read the last completed write, (``C,'' or
``consistency''---albeit poorly named) and replica availability, or a
guaranteed response, (``A'') in the presence of network partitions
(``P''). Brewer's Theorem has roots in decades of distributed database
research~\cite{davidson-survey} and has had a substantial impact on
recent large-scale distributed systems design~\cite{bigtable, pnuts,
  dynamo}: while CAP is narrowly scoped to the impossibility of
building highly available linearizable systems, it is often
interpreted to preclude a larger set of guarantees, including ACID
(transactional atomicity, consistency, isolation and durability
guarantees). We are unlikely to determine the exact cause of this
confusion, but it appears as early as the first public announcement of
Brewer's result, in which ''distributed databases'' appear as an
example of unavailable systems~\cite{brewer-slides}. While, in the
same document, Brewer is careful to note that consistency and
availability are a ``spectrum,'' all of ACID is often categorized as
unavailable~\cite{hn, foundation-article}.

Read Uncommitted is similar to the distributed systems
concept of replica convergence, in which all replicas for a data item
must end up with the same data item. This convergence is usually
achieved by picking a ``winning'' update, requiring a means of totally
ordering updates to each item; one can view Read Uncommitted as a
cross-item convergence property

This convergence property should be
considered mandatory given the spirit of existing literature on
isolation protocols: in all models we have encountered, the database
should behave as if there is some total order over
transactions. Indeed, non-convergent systems are remarkably difficult
to reason about.

(TODO: fix me--HotOS copy!)

Nonetheless, Coordinating transactional atomicity across replicas is
challenging. For example, if, as is common~\cite{readonly, eiger}, we
use a master to determine the correct set of updates to read, then the
system will not be available when clients are partitioned from the
master. Instead, we rely on decentralized \textit{background}
agreement to decide when to show new values, which can safely stall in
the presence of partitions. Each server keeps a known good value for
each data item $d$ it is assigned, $d_{good}$ and a set of pending
updates to $d$, $d_{pending}$. We use asynchronous agreement to move
updates from $d_{pending}$ to $d_{good}$: all of $d_{good}$'s
transactional siblings (or later values) are guaranteed present on all
replicas. Without aborts, this requires only one synchronous round
trip time (RTT).

\noindent\textit{Writes:} First, consider the case where transactions
do not internally abort. On commit, for each written data item $d$, we
send the last written value of $d$ ($d_v$) with the transaction ID and
$L_v$, a list of all data items and values written in the transaction,
to available replicas for $d$. The replicas immediately reply with a
response to \textit{commit}, place $d_v$ it in their respective
$d_{pending}$, and send a receipt to all replicas for items in
$L_v$. Once a server receives receipts from all replicas for all items
in $L_v$, the server sets $d_{good} = d_v$ if $d_v$'s ID is greater
than $d_{good}$'s ID. Accordingly, a new value will only appear in
$d_{good}$ when the other values written with $d_{good}$ ($L_v$) are
resident on every respective replica (though possibly in their
$d_{pending}$).\vspace{.5em}

\noindent\textit{Reads:} Each client maintains a vector of transaction
IDs $V$, with one entry per data item ($V(d)$). When a client reads a
new data item $d_i$, the server returns both $d_i$ and $L_v$, and, for
all data items $k \in L_v$, the client sets $V(k)$ to $d_i$'s ID. When
a client sends a read request for item $x$, it also sends $V(x)$, and
the replica returns \textit{either} $x_{good}$ if it matches $V(x)$ or
occurs after $V(x)$ in the transaction order or, if $x_{good}$ is
unsatisfactory, $V(x)$ from $x_{pending}$. If $V(x)$ is empty, the
server returns $x_{good}$.\vspace{.5em}

We can also consider arbitrary
application-defined partial orders, as in explicit
causality~\cite{explicit-socc}, if dependencies are specified at
commit time.

\noindent\textit{Aborts:} If we allow internal aborts, writes require
2 RTTs: one to check constraints and one to execute the above. Write
propagation and update visibility are achieved asynchronously, as in
the no-abort case.\vspace{.5em}

This implementation is entirely masterless and both reads and writes
do not block for coordination. One key property is that we do not, in general,
dictate when writes become visible (see: session guarantees,
\S\ref{sec:impossible}). Accordingly, it is highly available.\vspace{.5em}


The database tradition of providing ACID guarantees: atomicity,
consistency, isolation, and durability are, with few exceptions, not
addressed by the distributed systems literature. There are several
factors behind this occurrence, the least of which is that distributed
systems rarely consider multi-object guarantees, whereas ACID
transactions are frequently used to provide semantic guarantees across
multiple operations on multiple objects. While linearizability
(unfortunately often called ``atomicity'') ``composes'' across
multiple objects, a linearizable system does not provide ACID
``atomicity'' (which we will call ``transactional atomicity'' for
clarity): just because two writes are visible to all writers
immediately after they complete does not, on its own, provide any
guarantees about the mutual visibility of the two writes.

ecades of
research on semantics-based concurrency control and
coordination-reducing techniques such as escrow transactions and sagas
allow serializability in the presence of partial system knowledge or
otherwise reduce coordination cost. However, the majority of these
algorithms are intended to preserve application-level consistency,
which, for arbitrary applications and arbitrary sequence of
operations, cannot be ensured with high availability in the presence
of partitions.

 We might view the use of weak consistency is somewhat
of an ``arms race'': anecdotally, one major RDBMS vendor was forced to
lower their default isolation level in order to compare favorably in
out-of-the-box performance comparisons with its major competitor,
which had already lowered its default setting. Applications can guard
against inconsistency in a weakly isolated environment by performing
their own locking external to the database or by performing ad-hoc
concurrency control within the database. However, this appears
error-prone and, without further evidence, it remains somewhat
puzzling why this is indeed favorable to providing serializability
with in the database itself.

TRASH

We can accomplish these three requirements in two ways. First, clients
can locally cache their reads and writes, updating caches when they
read admissible replacements from
replicas~\cite{sessionguarantees}. Second, clients can ensure
\textit{stickiness} with groups~\cite{vogels-defs} (subject to the
same groups caveat as before).  For monotonic writes, clients should
generate increasing IDs for each transaction they perform. Caching and
ID generation are both available.

To provide writes follow reads,
severs (or clients) can buffer transaction writes until the
transactions the writes depend on have been written to all
replicas~\cite{cops}. If we consider a group model, each group can
independently apply transactions in order via a (possibly sharded)
log-shipping approach~\cite{causalmemory, cops, eiger, swift}.




What about existing systems?
* Database technology developed for single-node systems; gold standard: serializability
	* Serializability is not actually highly available; give an example!
	* Much of the database literature presumes serializability and does not consider high availability.
	* For the literature that doesn't presume serializability, it's not presented in a HA context?
* Consequence: traditional systems are not optimized for high availability
	* Consider two-phase locking in a distributed environment
	* As we will see (forward reference to Evaluation), many existing transactional systems encounter similar difficulties
* Key question in this paper: What transactional semantics are highly available, and which aren't?
	* Side note: there are infinite incomparable consistency models (e.g., always return 2, always return 3, â€¦)
	* Our goal is to unify distributed systems literature with ACID transaction model.
* Argument: Highly Available Transactional Systems (HATS) require rethinking existing models. This work is a first step.

In this sense, HATs are similar to RAID: optimizing for graceful
handling of a worst-case failure scenario improves average-case
performance.

IV. HATS and ACID (4pg)

We will show what semantics are available in HATS as well as which aren't. Our strategy will be to build up a set of properties until we reach a point of unavailability. We will start with isolation and atomicity since they are well-defined in the literature and most meaty.

A. *What's Available in Isolation and Atomicity?*

* We can prevent Dirty Write phenomena by consistently ordering transactions
	* This is basically a cross-data item convergency property, as are found in eventually consistent systems!
* Read Committed
	* Don't read dirty data by never exposing dirty data to readers!
* ANSI Repeatable Read => rename to cut isolation
	* Repeatable Read is a tricky guarantee. In ANSI SQL Spec, rather weak, but in follow-on work, it's pretty strong.
	* The property that the ANSI SQL spec talks about is about reading a "snapshot" of data items, along with your own writes.
		* A "snapshot" describes a "consistent cut" across data items; we'll call it "cut isolation"--when paired with below guarantees, makes sense.
	* This doesn't provide any constraints on writes.

* There are several properties that aren't discussed in the formal literature on isolation guarantees but which are really useful.

* Transactional atomicity: "A" in ACID
	* Once a transaction reads one of another transactions's writes, its subsequent reads will return the transactions's other writes (or a suitable "later" write).
	* Be really pedagogical here: "transactional atomicity" versus "distributed linearizability" both called "atomicity"; we actually explore the differences later, in Discussion section.
	* Talk about implementation here: it's basically uniform eager reliable delivery from distributed systems literature!
	* Note that this doesn't make recency guarantees (forward reference to later section on "impossibility")

* Session guarantees give useful guarantees within and across transactions
	* Without them, cut isolation is sort of meaningless: we can always just return NULL!
	* Several properties: monotonic writes, monotonic reads, writes follow reads, read your writes
	* We can define them within a transaction only (e.g., transactional monotonic writes) or across subsequent transactions by the same client (e.g., client monotonic writes).

* Session guarantees are tricky
	* You can implement all but read-your-writes in a R-HA system
		* Never show a write until all replicas in the system have seen it!
		* This means that, if a client switches replicas, then the replica will have a satisfying set of writes.
                * Take S3 as an example of a system where stickiness coudl have helped, but no one really talked about it!
		* Downside: when do writes become visible? Only when all replicas have seen it!
		* Side note: assuming that, if replicas can enter and leave, they can only become active once they "catch up" to global lower bound
			* We leave dynamic replica selection as Future Work (N.B. in APEs!)
	* Read-your-writes requires S-HA
		* Example: partition a client from all but one replica, have the client issue a write, which has to commit. Next, lift the partition between the client and the other replicas and partition the client and its previous replica. It can't read it's own write!
		* This also means that causality, which is MR+MW+WFR+RYW is unavailable!
		* S-HA is *doable* but it does result in substantially lowered unavailability unless one caches (e.g., bolt-on causal consistency)

\noindent\textit{Groups:} We can optimize write visibility delay by
partitioning servers and clients into groups, such that each group
contains a fully replicated set of data items and all clients within a
group contact only the servers in the group. Once all transaction
values are present within a group, values can be installed as
$d_{good}$ (as opposed to once they are present on all replicas). For
example, in a multi-datacenter setting, all clients and servers within
a datacenter may form a group. However, group-based atomicity is not
highly available according to our definition unless clients and
servers in a group fail together, as is often assumed in a
geo-replicated context~\cite{cops, eiger}.

* What do we have?
	* In Adya, we get up to Causal+Cut Isolation for S-HA, and PL-2 for R-HA.
	* In distributed systems terminology, in S-HA we have causal consistency but each transactions' updates are a cycle in the happens-before graph!
		* Stress that this is a big unification of the existing models.
	* Recap, pedagogically, why this is highly available and what this means: no locks, no central coordination, no need for RTTs; bring back to Section II.

B. *What's not available in Isolation?*

Now, at least in terms of the existing literature, we hit the limits.

Let's sketch out a few conditions, then we'll discuss them later:

Now refer to Adya's chart. No PL-SI, PL-SS, PL-2.99, etc.

C. *What's available in consistency?*

* In general, we can't maintain correctness conditions over arbitrary data items.
	* This is due to serializability problems.
	* Uniqueness, for example, is out the window

* We can evaluate locally checkable correctness criteria (e.g., check for null)
	(QUESTION: should we save this for APEs?)

* However, with semantic knowledge, we can do a little bit better
	* Commutative updates and logical monotonicity are fine; e.g., write-write conflicts don't matter
	
Example: In TPC-C New Order, the new order id assignment isn't commutative, tough. but the inventory checking *is*!

D. Durability

* If you want data to survive *F* failures, you'll have to replicate to *F* replicas.
	* This is pretty easy.

E. Summary

* Left with a bunch of binary properties: 
R-HA: Prevent Dirty Write, Read Committed, Cut Isolation, Transactional Atomicity, Transactional Monotonic Reads, Transactional Monotonic Writes, Transactional Writes-Follow-Reads, Client Monotonic Reads, Client Monotonic Writes, Client Writes-Follow-Reads
S-HA: Client Read Your Writes, Transactional Read Your Writes

* Combining all of the above results in the strongest models we've yet seen. No

*Discussion*
