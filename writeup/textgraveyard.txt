
TRASH

We can accomplish these three requirements in two ways. First, clients
can locally cache their reads and writes, updating caches when they
read admissible replacements from
replicas~\cite{sessionguarantees}. Second, clients can ensure
\textit{stickiness} with groups~\cite{vogels-defs} (subject to the
same groups caveat as before).  For monotonic writes, clients should
generate increasing IDs for each transaction they perform. Caching and
ID generation are both available.

To provide writes follow reads,
severs (or clients) can buffer transaction writes until the
transactions the writes depend on have been written to all
replicas~\cite{cops}. If we consider a group model, each group can
independently apply transactions in order via a (possibly sharded)
log-shipping approach~\cite{causalmemory, cops, eiger, swift}.




What about existing systems?
* Database technology developed for single-node systems; gold standard: serializability
	* Serializability is not actually highly available; give an example!
	* Much of the database literature presumes serializability and does not consider high availability.
	* For the literature that doesn't presume serializability, it's not presented in a HA context?
* Consequence: traditional systems are not optimized for high availability
	* Consider two-phase locking in a distributed environment
	* As we will see (forward reference to Evaluation), many existing transactional systems encounter similar difficulties
* Key question in this paper: What transactional semantics are highly available, and which aren't?
	* Side note: there are infinite incomparable consistency models (e.g., always return 2, always return 3, â€¦)
	* Our goal is to unify distributed systems literature with ACID transaction model.
* Argument: Highly Available Transactional Systems (HATS) require rethinking existing models. This work is a first step.

In this sense, HATs are similar to RAID: optimizing for graceful
handling of a worst-case failure scenario improves average-case
performance.

IV. HATS and ACID (4pg)

We will show what semantics are available in HATS as well as which aren't. Our strategy will be to build up a set of properties until we reach a point of unavailability. We will start with isolation and atomicity since they are well-defined in the literature and most meaty.

A. *What's Available in Isolation and Atomicity?*

* We can prevent Dirty Write phenomena by consistently ordering transactions
	* This is basically a cross-data item convergency property, as are found in eventually consistent systems!
* Read Committed
	* Don't read dirty data by never exposing dirty data to readers!
* ANSI Repeatable Read => rename to cut isolation
	* Repeatable Read is a tricky guarantee. In ANSI SQL Spec, rather weak, but in follow-on work, it's pretty strong.
	* The property that the ANSI SQL spec talks about is about reading a "snapshot" of data items, along with your own writes.
		* A "snapshot" describes a "consistent cut" across data items; we'll call it "cut isolation"--when paired with below guarantees, makes sense.
	* This doesn't provide any constraints on writes.

* There are several properties that aren't discussed in the formal literature on isolation guarantees but which are really useful.

* Transactional atomicity: "A" in ACID
	* Once a transaction reads one of another transactions's writes, its subsequent reads will return the transactions's other writes (or a suitable "later" write).
	* Be really pedagogical here: "transactional atomicity" versus "distributed linearizability" both called "atomicity"; we actually explore the differences later, in Discussion section.
	* Talk about implementation here: it's basically uniform eager reliable delivery from distributed systems literature!
	* Note that this doesn't make recency guarantees (forward reference to later section on "impossibility")

* Session guarantees give useful guarantees within and across transactions
	* Without them, cut isolation is sort of meaningless: we can always just return NULL!
	* Several properties: monotonic writes, monotonic reads, writes follow reads, read your writes
	* We can define them within a transaction only (e.g., transactional monotonic writes) or across subsequent transactions by the same client (e.g., client monotonic writes).

* Session guarantees are tricky
	* You can implement all but read-your-writes in a R-HA system
		* Never show a write until all replicas in the system have seen it!
		* This means that, if a client switches replicas, then the replica will have a satisfying set of writes.
                * Take S3 as an example of a system where stickiness coudl have helped, but no one really talked about it!
		* Downside: when do writes become visible? Only when all replicas have seen it!
		* Side note: assuming that, if replicas can enter and leave, they can only become active once they "catch up" to global lower bound
			* We leave dynamic replica selection as Future Work (N.B. in APEs!)
	* Read-your-writes requires S-HA
		* Example: partition a client from all but one replica, have the client issue a write, which has to commit. Next, lift the partition between the client and the other replicas and partition the client and its previous replica. It can't read it's own write!
		* This also means that causality, which is MR+MW+WFR+RYW is unavailable!
		* S-HA is *doable* but it does result in substantially lowered unavailability unless one caches (e.g., bolt-on causal consistency)

\noindent\textit{Groups:} We can optimize write visibility delay by
partitioning servers and clients into groups, such that each group
contains a fully replicated set of data items and all clients within a
group contact only the servers in the group. Once all transaction
values are present within a group, values can be installed as
$d_{good}$ (as opposed to once they are present on all replicas). For
example, in a multi-datacenter setting, all clients and servers within
a datacenter may form a group. However, group-based atomicity is not
highly available according to our definition unless clients and
servers in a group fail together, as is often assumed in a
geo-replicated context~\cite{cops, eiger}.

* What do we have?
	* In Adya, we get up to Causal+Cut Isolation for S-HA, and PL-2 for R-HA.
	* In distributed systems terminology, in S-HA we have causal consistency but each transactions' updates are a cycle in the happens-before graph!
		* Stress that this is a big unification of the existing models.
	* Recap, pedagogically, why this is highly available and what this means: no locks, no central coordination, no need for RTTs; bring back to Section II.

B. *What's not available in Isolation?*

Now, at least in terms of the existing literature, we hit the limits.

Let's sketch out a few conditions, then we'll discuss them later:

Now refer to Adya's chart. No PL-SI, PL-SS, PL-2.99, etc.

C. *What's available in consistency?*

* In general, we can't maintain correctness conditions over arbitrary data items.
	* This is due to serializability problems.
	* Uniqueness, for example, is out the window

* We can evaluate locally checkable correctness criteria (e.g., check for null)
	(QUESTION: should we save this for APEs?)

* However, with semantic knowledge, we can do a little bit better
	* Commutative updates and logical monotonicity are fine; e.g., write-write conflicts don't matter
	
Example: In TPC-C New Order, the new order id assignment isn't commutative, tough. but the inventory checking *is*!

D. Durability

* If you want data to survive *F* failures, you'll have to replicate to *F* replicas.
	* This is pretty easy.

E. Summary

* Left with a bunch of binary properties: 
R-HA: Prevent Dirty Write, Read Committed, Cut Isolation, Transactional Atomicity, Transactional Monotonic Reads, Transactional Monotonic Writes, Transactional Writes-Follow-Reads, Client Monotonic Reads, Client Monotonic Writes, Client Writes-Follow-Reads
S-HA: Client Read Your Writes, Transactional Read Your Writes

* Combining all of the above results in the strongest models we've yet seen. No

*Discussion*
